{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KjUvZzUN7v5a"
      },
      "source": [
        "<font size=6>**Advanced RAG**</font>\n",
        "\n",
        "<font size=5>**Multi-Modal RAG for Healthcare**</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Setup\n",
        "\n",
        "This notebook assumes the following:\n",
        "- Python 3.10+\n",
        "- An OpenAI API key set as an environment variable:\n",
        "  ```bash\n",
        "  export OPENAI_API_KEY=\"your-key\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YWVPD63v7v25"
      },
      "source": [
        "**Solution Approach**\n",
        "\n",
        "The core of the solution involves the creation of an AI-based Advanced Retrieval-Augmented Generation (RAG) System that encompasses the following key components:\n",
        "\n",
        "1. **Development of a Text and Image-Based Knowledge Base:** This will compile comprehensive information about vitamins and nutrients, supplemented with relevant images to enrich user understanding.\n",
        "2. **Implementation of Reranking Methodology:** This process will refine the AI system’s ability to recommend the most relevant responses to user queries, thereby enhancing accuracy and user satisfaction.\n",
        "3. **Query Expansion Techniques:** These will improve the AI’s comprehension of user queries, making it more efficient in providing precise information tailored to individual needs."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L3h68HDSt5O3"
      },
      "source": [
        "## **Setup**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "VUKCCwXZNc31",
        "outputId": "92317108-3cf6-4bea-beeb-592b488fe82d"
      },
      "outputs": [],
      "source": [
        "# @title Run this cell => Restart the session => Start executing the below cells **(DO NOT EXECUTE THIS CELL AGAIN)**\n",
        "\n",
        "!pip install -q langchain==0.3.21 \\\n",
        "                huggingface_hub==0.29.3 \\\n",
        "                openai==1.68.2 \\\n",
        "                chromadb==0.6.3 \\\n",
        "                langchain-community==0.3.20 \\\n",
        "                langchain_openai==0.3.10 \\\n",
        "                lark==1.2.2\\\n",
        "                rank_bm25==0.2.2\\\n",
        "                numpy==2.2.4 \\\n",
        "                scipy==1.15.2 \\\n",
        "                scikit-learn==1.6.1 \\\n",
        "                transformers==4.50.0 \\\n",
        "                pypdf==5.4.0 \\\n",
        "                markdown-pdf==1.7 \\\n",
        "                sentence_transformers==4.0.0 \\\n",
        "                torch==2.6.0+cu124\n",
        "\n",
        "\n",
        "%pip install --upgrade chromadb\n",
        "%pip install pillow\n",
        "%pip install open-clip-torch\n",
        "%pip install matplotlib"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TIidjgK-M95r"
      },
      "outputs": [],
      "source": [
        "import zipfile\n",
        "import os\n",
        "\n",
        "zip_path = \"path\"\n",
        "extract_to = \"./\"   # current notebook directory\n",
        "\n",
        "with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(extract_to)\n",
        "\n",
        "print(\"Extraction complete!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "vQSyBaLIqRXp"
      },
      "outputs": [],
      "source": [
        "# @title Loading the `config.json` file\n",
        "import json\n",
        "import os\n",
        "\n",
        "# Load the JSON file and extract values\n",
        "file_name = 'config.json'\n",
        "with open(file_name, 'r') as file:\n",
        "    config = json.load(file)\n",
        "    os.environ['OPENAI_API_KEY'] = config.get(\"API_KEY\") # Loading the API Key\n",
        "    os.environ[\"OPENAI_BASE_URL\"] = config.get(\"OPENAI_API_BASE\") # Loading the API Base Url"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "uBnakU8dqbBg"
      },
      "outputs": [],
      "source": [
        "# @title Defining the Embedding Model - Using `text-embedding-ada-002` Model\n",
        "from langchain_openai import OpenAIEmbeddings\n",
        "embeddings = OpenAIEmbeddings(model=\"text-embedding-ada-002\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "0J45TvtIt23i"
      },
      "outputs": [],
      "source": [
        "# @title Defining the LLM Model - Using `gpt-4o-mini` Model\n",
        "from langchain_openai import ChatOpenAI\n",
        "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BdpwaV-rIU67"
      },
      "source": [
        "## **Step 1 : Loading the PDF and storing it in the vectorDB**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "yn9v44iXttUC"
      },
      "outputs": [],
      "source": [
        "from langchain.document_loaders import PyPDFLoader\n",
        "\n",
        "# Reading the NOFO Document\n",
        "pdf_file = \"path/to/your/document.pdf\"\n",
        "pdf_loader = PyPDFLoader(pdf_file);\n",
        "text_data = pdf_loader.load()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "8dvMTgtCttRU",
        "outputId": "f848f06e-9e6c-4490-e7f9-f6384337ddc5"
      },
      "outputs": [],
      "source": [
        "from langchain.vectorstores import Chroma\n",
        "\n",
        "text_vectorstore = Chroma(\n",
        "    collection_name=\"vitamin_and_minerals\",\n",
        "    embedding_function=embeddings)\n",
        "\n",
        "text_vectorstore.add_documents(documents=text_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "k7T70uVisJJp"
      },
      "outputs": [],
      "source": [
        "vanilla_retriever = text_vectorstore.as_retriever(search_kwargs={\"k\": 10})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_F34PZSwIU2Y"
      },
      "source": [
        "## **Step 2 : Loading the Images along with metadata and storing them in the vectorDB**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "uXneZb4NMPFR"
      },
      "outputs": [],
      "source": [
        "import chromadb\n",
        "from chromadb.utils.embedding_functions import OpenCLIPEmbeddingFunction\n",
        "from chromadb.utils.data_loaders import ImageLoader\n",
        "from matplotlib import pyplot as plt\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-4B_jfXcMPDI"
      },
      "outputs": [],
      "source": [
        "# Create database file at folder \"my_vectordb\" or load into client if exists\n",
        "chroma_client = chromadb.PersistentClient(path=\"my_vectordb\")\n",
        "\n",
        "# Instantiate image loader helper\n",
        "image_loader = ImageLoader()\n",
        "\n",
        "# Instantiate multimodal embedding function\n",
        "image_embedding_function = OpenCLIPEmbeddingFunction()\n",
        "\n",
        "# Create the collection, aka vector database. Or, if database already exist, then use it. Specify the model that we want to use to do the embedding\n",
        "multimodal_db = chroma_client.get_or_create_collection(name=\"multimodal_db\", embedding_function=image_embedding_function, data_loader=image_loader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V1TNsR45OqkE",
        "outputId": "f838247d-0a74-4bf3-d125-fb5864dd0f8e"
      },
      "outputs": [],
      "source": [
        "multimodal_db.count()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "print(os.listdir(\"path/to/your/image/folder\"))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CrZPiKJWOqhk",
        "outputId": "beb6567e-7e01-497b-9ce8-fc766bec618a"
      },
      "outputs": [],
      "source": [
        "from PIL import Image\n",
        "import numpy as np\n",
        "\n",
        "import os\n",
        "\n",
        "folder = \"path/to/your/image/folder\"\n",
        "\n",
        "image_paths = [f\"{folder}/{file}\" for file in os.listdir(folder)]\n",
        "image_paths\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HoLjOBUrOqe_",
        "outputId": "21628bf6-d06f-4c7c-931b-34586f2013b9"
      },
      "outputs": [],
      "source": [
        "# Defining Metadata\n",
        "Metadata = []\n",
        "for file in os.listdir(\"path/to/your/image/folder\"):\n",
        "  Metadata.append({'Vitamin':file.split(\"-\")[0][-1],\n",
        "                   'info': f'The images shows the sources of Vitamin {file.split(\"-\")[0][-1]}'})\n",
        "\n",
        "Metadata"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "UZzPZKbHOqoU"
      },
      "outputs": [],
      "source": [
        "# Use .add() to add a new record or .update() to update existing record\n",
        "multimodal_db.add(\n",
        "    ids=[str(x) for x in range(len(os.listdir(\"path/to/your/image/folder\")))],\n",
        "    uris = image_paths,\n",
        "    metadatas=Metadata\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m4SynnGyOqZa",
        "outputId": "7e56829d-231e-4415-a1e8-178bbd72bd8d"
      },
      "outputs": [],
      "source": [
        "multimodal_db.count()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "DEJASPOGSYuc"
      },
      "outputs": [],
      "source": [
        "# Simple function to print the results of a query.\n",
        "# The 'results' is a dict {ids, distances, data, ...}\n",
        "# Each item in the dict is a 2d list.\n",
        "def print_query_results(query_list: list, query_results: dict)->None:\n",
        "    result_count = len(query_results['ids'][0])\n",
        "\n",
        "    for i in range(len(query_list)):\n",
        "        for j in range(result_count):\n",
        "            id       = query_results[\"ids\"][i][j]\n",
        "            distance = query_results['distances'][i][j]\n",
        "            data     = query_results['data'][i][j]\n",
        "            document = query_results['documents'][i][j]\n",
        "            metadata = query_results['metadatas'][i][j]\n",
        "            uri      = query_results['uris'][i][j]\n",
        "\n",
        "            print(f'id: {id}, distance: {distance}, metadata: {metadata}, document: {document}')\n",
        "\n",
        "            # Display image, the physical file must exist at URI.\n",
        "            # (ImageLoader loads the image from file)\n",
        "            print(f'data: {uri}')\n",
        "            plt.imshow(data)\n",
        "            plt.axis(\"off\")\n",
        "            plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "dW3Sout7SPoN"
      },
      "outputs": [],
      "source": [
        "def get_image(query_texts):\n",
        "# Query vector db\n",
        "    query_results = multimodal_db.query(\n",
        "        query_texts = query_texts,\n",
        "        n_results=2,\n",
        "        include=['documents', 'distances', 'metadatas', 'data', 'uris'],\n",
        "    )\n",
        "\n",
        "    print_query_results(query_texts, query_results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 864
        },
        "id": "SHF5F07CSPYU",
        "outputId": "453f87b6-113f-4789-b310-ea50e3fa8af1"
      },
      "outputs": [],
      "source": [
        "get_image(['Citrus fruits have which common vitamins'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bkj0duTCIgqS"
      },
      "source": [
        "## **Reranking**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "id": "CfO5StuFruyf"
      },
      "outputs": [],
      "source": [
        "from langchain_community.cross_encoders import HuggingFaceCrossEncoder\n",
        "crossencoder = HuggingFaceCrossEncoder(model_name=\"cross-encoder/ms-marco-MiniLM-L-6-v2\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "id": "JO6EkBpGuEOp"
      },
      "outputs": [],
      "source": [
        "from langchain.retrievers.document_compressors import CrossEncoderReranker\n",
        "reranker = CrossEncoderReranker(model=crossencoder, top_n=5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "id": "BG6WiBTUrruw"
      },
      "outputs": [],
      "source": [
        "from langchain.retrievers import ContextualCompressionRetriever\n",
        "reranker_retriever = ContextualCompressionRetriever(\n",
        "    base_compressor=reranker, base_retriever=vanilla_retriever\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lmACBJ5rIgie"
      },
      "source": [
        "## **User Query Expansion**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "id": "5Ejs1GoMt1eJ"
      },
      "outputs": [],
      "source": [
        "# Query Expansion for User_query\n",
        "\n",
        "def query_expansion(user_query):\n",
        "    query_enhancement = f\"\"\"\n",
        "    You are an expert in information retrieval systems, particularly skilled in enhancing queries for document search efficiency.\n",
        "    Perform query expansion on the received question by considering alternative phrasings or synonyms commonly used in document retrieval contexts.\n",
        "    If there are multiple ways to phrase the user's question or common synonyms for key terms, provide several reworded versions.\n",
        "\n",
        "    If there are acronyms or words you are not familiar with, do not try to rephrase them.\n",
        "\n",
        "    Return at least 3 versions of the question as a list.\n",
        "    Generate only a list of questions. Do not mention anything before or after the list.\n",
        "\n",
        "    Question:\n",
        "    {user_query}\n",
        "    \"\"\"\n",
        "\n",
        "\n",
        "    new_question = llm.invoke(query_enhancement)\n",
        "    return (new_question.content)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ehe_bldfIUyZ"
      },
      "source": [
        "## **Step 3 : Retriever which can fetch the data from (PDF + Images) and return this to the user**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vUwQqFvIwGjA",
        "outputId": "494d819f-dfdd-4e68-caea-c3cd8e40f866"
      },
      "outputs": [],
      "source": [
        "# Query Expansion\n",
        "multipule_queries = query_expansion(user_query)\n",
        "print(multipule_queries)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HDJgiv_l40Xx",
        "outputId": "2567ee8e-5581-4dee-8a79-77d5e912e1b6"
      },
      "outputs": [],
      "source": [
        "# Calling the vanilla retriever\n",
        "vanilla_responses = vanilla_retriever.get_relevant_documents(multipule_queries)\n",
        "\n",
        "# We can see the results are not sorted\n",
        "context_query_pairs_for_scoring = [[multipule_queries, doc_text.page_content] for doc_text in vanilla_responses]\n",
        "crossencoder.score(context_query_pairs_for_scoring)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PbDO9uy85K1S"
      },
      "source": [
        "**In the above cell, we can observe that we fetched 10 chunks and they are not sorted. Now, we will be following the re-ranking approach to fetch the 5 most relevant chunks from these 10.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 99,
      "metadata": {
        "id": "xsVepYitspRo"
      },
      "outputs": [],
      "source": [
        "# Calling the reranking retriever\n",
        "reranked_responses = reranker_retriever.get_relevant_documents(multipule_queries)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NlFMYahd3bkX",
        "outputId": "b6461e70-819c-4bf8-8f82-d0b4e92c1df6"
      },
      "outputs": [],
      "source": [
        "# We can see the results are sorted\n",
        "context_query_pairs_for_scoring = [[multipule_queries, doc_text.page_content] for doc_text in reranked_responses]\n",
        "crossencoder.score(context_query_pairs_for_scoring)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 101,
      "metadata": {
        "id": "8O2Z2pe0spO7"
      },
      "outputs": [],
      "source": [
        "prompt = f\"\"\"\n",
        "You are an expert AI assistant for question-answering tasks.\n",
        "Use the following pieces of retrieved context to answer the question.\n",
        "\n",
        "### Context:\n",
        "{reranked_responses}\n",
        "\n",
        "### Question:\n",
        "{multipule_queries}\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 102,
      "metadata": {
        "id": "-dcFqK0mxQCZ"
      },
      "outputs": [],
      "source": [
        "llm_response = llm.invoke(prompt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "jdCjNJ92spME",
        "outputId": "acbce8e6-f04e-4c74-cd96-c3a85ef0246d"
      },
      "outputs": [],
      "source": [
        "print(\"Answer: \\n\", llm_response.content)\n",
        "print(\"=\"*50)\n",
        "print(\"Relevant Images: \\n\")\n",
        "get_image([llm_response.content])"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python (Algorithms-Kernel)",
      "language": "python",
      "name": "algorithms-kernel"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.23"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
